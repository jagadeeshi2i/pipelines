{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Pipeline : PyTorch BERT News Classfication\n",
    "\n",
    "This notebook shows PyTorch BERT end-to-end news classification example using Kubeflow Pipelines.\n",
    "\n",
    "\n",
    "An example notebook that demonstrates how to:\n",
    "\n",
    "* Get different tasks needed for the pipeline\n",
    "* Create a Kubeflow pipeline\n",
    "* Include Pytorch KFP components to preprocess, train, visualize and deploy the model in the pipeline\n",
    "* Submit a job for execution\n",
    "* Query(prediction and explain) the final deployed model\n",
    "* Interpretation of the model using the Captum Insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: kfp 1.0.4\n",
      "Uninstalling kfp-1.0.4:\n",
      "  Successfully uninstalled kfp-1.0.4\n",
      "Collecting kfp\n",
      "  Downloading kfp-1.6.4.tar.gz (225 kB)\n",
      "\u001b[K     |████████████████████████████████| 225 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py<=0.11,>=0.9\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 81.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.8/site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: google-cloud-storage<2,>=1.20.0 in /opt/conda/lib/python3.8/site-packages (from kfp) (1.37.1)\n",
      "Requirement already satisfied: kubernetes<13,>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from kfp) (10.0.1)\n",
      "Collecting google-api-python-client<2,>=1.7.8\n",
      "  Downloading google_api_python_client-1.12.8-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 2.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.8/site-packages (from kfp) (1.28.1)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied: cloudpickle<2,>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from kfp) (1.6.0)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2\n",
      "  Downloading kfp-server-api-1.6.0.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 47.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jsonschema<4,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.8/site-packages (from kfp) (0.8.9)\n",
      "Requirement already satisfied: click<8,>=7.1.1 in /opt/conda/lib/python3.8/site-packages (from kfp) (7.1.2)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.8/site-packages (from kfp) (1.2.12)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in /opt/conda/lib/python3.8/site-packages (from kfp) (0.1.9)\n",
      "Collecting docstring-parser<1,>=0.7.3\n",
      "  Downloading docstring_parser-0.8.1.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kfp-pipeline-spec<0.2.0,>=0.1.8\n",
      "  Downloading kfp_pipeline_spec-0.1.8-py3-none-any.whl (27 kB)\n",
      "Collecting fire<1,>=0.3.1\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 71.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.8/site-packages (from kfp) (3.15.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py<=0.11,>=0.9->kfp) (1.15.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.8/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.12.1)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting uritemplate<4dev,>=3.0.0\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 63.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-api-core<2dev,>=1.21.0 in /opt/conda/lib/python3.8/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (1.26.3)\n",
      "Collecting google-auth-httplib2>=0.0.3\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.8/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (49.6.0.post20210108)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (1.53.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.8/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (20.9)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.8/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (2021.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.8/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (2.25.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.1->kfp) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.1->kfp) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=1.2.0 in /opt/conda/lib/python3.8/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (1.2.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (1.6.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.8/site-packages (from google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage<2,>=1.20.0->kfp) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage<2,>=1.20.0->kfp) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage<2,>=1.20.0->kfp) (2.20)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /opt/conda/lib/python3.8/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (2.4.7)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema<4,>=3.0.1->kfp) (20.3.0)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.8/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.8/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.8/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.1)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.8/site-packages (from kubernetes<13,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.8/site-packages (from kubernetes<13,>=8.0.0->kfp) (0.58.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (4.0.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.36.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib->kubernetes<13,>=8.0.0->kfp) (3.1.0)\n",
      "Building wheels for collected packages: kfp, docstring-parser, fire, kfp-server-api, termcolor\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.6.4-py3-none-any.whl size=307978 sha256=3a2b56ad8d214b1e73311947fa8bf240aea895996097e50a54bfd360e51df52d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ezyarnlu/wheels/94/27/d3/4e61074deae41e0ef5f166343fc7540eb85536c3d49f4cd25f\n",
      "  Building wheel for docstring-parser (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docstring-parser: filename=docstring_parser-0.8.1-py3-none-any.whl size=19678 sha256=a63bf6b745a8a550f94b34f7174a2e69a2ae1135a2609a683696181afd26eb1d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ezyarnlu/wheels/7a/06/c4/9b2f0146899e8d1e7748897e42ad5412b6a025513f89cc4a0f\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115928 sha256=d1360aa88b08a20f854a6eb7e78690fdccdc4c97bb114137639463e2f4b23f70\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ezyarnlu/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-1.6.0-py3-none-any.whl size=92524 sha256=ea1c05bda560adad886ae1c27f6c222a08cb7d0d491d8acc820297d2447b26a3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ezyarnlu/wheels/73/72/bd/804c3bcea41a99dc328a623d003ba9d7d243f2a59a767ef28c\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=84ef768ba31cbc0d444c5a80fd2b526da18200887d2b27711a59658e6f3d409c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ezyarnlu/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built kfp docstring-parser fire kfp-server-api termcolor\n",
      "Installing collected packages: httplib2, uritemplate, termcolor, google-auth-httplib2, kfp-server-api, kfp-pipeline-spec, google-api-python-client, fire, docstring-parser, absl-py, kfp\n",
      "  Attempting uninstall: kfp-server-api\n",
      "    Found existing installation: kfp-server-api 1.0.4\n",
      "    Uninstalling kfp-server-api-1.0.4:\n",
      "      Successfully uninstalled kfp-server-api-1.0.4\n",
      "Successfully installed absl-py-0.11.0 docstring-parser-0.8.1 fire-0.4.0 google-api-python-client-1.12.8 google-auth-httplib2-0.1.0 httplib2-0.19.1 kfp-1.6.4 kfp-pipeline-spec-0.1.8 kfp-server-api-1.6.0 termcolor-1.1.0 uritemplate-3.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall -y kfp\n",
    "! pip install --no-cache-dir kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kfp\n",
    "import json\n",
    "import os\n",
    "from kfp.onprem import use_k8s_secret\n",
    "from kfp import components\n",
    "from kfp.components import load_component_from_file, load_component_from_url, InputPath\n",
    "from kfp import dsl\n",
    "from kfp import compiler\n",
    "\n",
    "kfp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter your gateway and the cookie\n",
    "[Use this extension on chrome to get token]( https://chrome.google.com/webstore/detail/editthiscookie/fngmhnnpilhplaeedifhccceomclgfbg?hl=en)\n",
    "\n",
    "![image.png](./image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update values for the ingress gateway and auth session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INGRESS_GATEWAY='http://istio-ingressgateway.istio-system.svc.cluster.local'\n",
    "AUTH=\"MTYyNDg3MTcyMXxOd3dBTkZVelZGbFBUVGRHUzFaRlYwTTBXa0pWUWtaV1dsRlBSVmRWVEZGQk5GZE5SRWMyVTFKRlJGaFBUbGRaVkZSTlRFeENRMEU9fPvSztBkZk6BMstONeAV17CtIWSkjm394Irt1xuxzudI\"\n",
    "NAMESPACE=\"kubeflow-user-example-com\"\n",
    "COOKIE=\"authservice_session=\"+AUTH\n",
    "EXPERIMENT=\"Default\"\n",
    "dist_volume = 'dist-vol'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Log bucket and Tensorboard Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIO_ENDPOINT=\"http://minio-service.kubeflow:9000\"\n",
    "LOG_BUCKET=\"mlpipeline\"\n",
    "TENSORBOARD_IMAGE=\"public.ecr.aws/y1x1p2u5/tboard:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(host=INGRESS_GATEWAY+\"/pipeline\", cookies=COOKIE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://istio-ingressgateway.istio-system.svc.cluster.local/pipeline/#/experiments/details/ba9b7266-2b1c-4729-afcd-be808c25c5af\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'created_at': datetime.datetime(2021, 6, 21, 13, 13, 6, tzinfo=tzlocal()),\n",
       " 'description': None,\n",
       " 'id': 'ba9b7266-2b1c-4729-afcd-be808c25c5af',\n",
       " 'name': 'Default',\n",
       " 'resource_references': [{'key': {'id': 'kubeflow-user-example-com',\n",
       "                                  'type': 'NAMESPACE'},\n",
       "                          'name': None,\n",
       "                          'relationship': 'OWNER'}],\n",
       " 'storage_state': 'STORAGESTATE_AVAILABLE'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_experiment(EXPERIMENT)\n",
    "experiments = client.list_experiments(namespace=NAMESPACE)\n",
    "my_experiment = experiments.experiments[0]\n",
    "my_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOY_NAME=\"bertserve\"\n",
    "MODEL_NAME=\"bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_tensorboard_op = load_component_from_file(\n",
    "    \"common/tensorboard/component.yaml\"\n",
    ")\n",
    "prep_op = components.load_component_from_file(\n",
    "    \"bert/yaml/pre_process/component.yaml\"\n",
    ")\n",
    "train_op = components.load_component_from_file(\n",
    "    \"bert/yaml/train/component.yaml\"\n",
    ")\n",
    "deploy_op = load_component_from_file(\n",
    "    \"common/deploy/component.yaml\"\n",
    ")\n",
    "minio_op = components.load_component_from_file(\n",
    "    \"common/minio/component.yaml\"\n",
    ")\n",
    "pytorch_job_op = load_component_from_file(\n",
    "    \"common/pytorch_job/component.yaml\"\n",
    ")\n",
    "cp_op = load_component_from_file(\n",
    "    \"common/copy/component.yaml\"\n",
    ")\n",
    "ls_op = load_component_from_file(\n",
    "    \"common/list/component.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes.client.models import V1Volume, V1PersistentVolumeClaimVolumeSource\n",
    "def create_dist_pipeline():\n",
    "    kubernetes_create_pvc_op(pvc_name=dist_volume, storage_size= \"20Gi\", namespace=NAMESPACE)\n",
    "\n",
    "create_volume_run = client.create_run_from_pipeline_func(create_dist_pipeline, arguments={})\n",
    "create_volume_run.wait_for_run_completion()\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"Training pipeline\", description=\"Sample training job test\")\n",
    "def pytorch_bert(\n",
    "    minio_endpoint=MINIO_ENDPOINT,\n",
    "    log_bucket=LOG_BUCKET,\n",
    "    log_dir=f\"/tensorboard/logs/{dsl.RUN_ID_PLACEHOLDER}\",\n",
    "    mar_path=f\"mar/{dsl.RUN_ID_PLACEHOLDER}/model-store\",\n",
    "    config_prop_path=f\"mar/{dsl.RUN_ID_PLACEHOLDER}/config\",\n",
    "    model_uri=f\"s3://mlpipeline/mar/{dsl.RUN_ID_PLACEHOLDER}\",\n",
    "    tf_image=TENSORBOARD_IMAGE,\n",
    "    deploy=DEPLOY_NAME,\n",
    "    namespace=NAMESPACE,\n",
    "    confusion_matrix_log_dir=f\"confusion_matrix/{dsl.RUN_ID_PLACEHOLDER}/\",\n",
    "    num_samples=1000,\n",
    "    max_epochs=1,\n",
    "    gpus=1,\n",
    "    num_nodes=2\n",
    "):\n",
    "    \n",
    "  \n",
    "    prepare_tb_task = prepare_tensorboard_op(\n",
    "        log_dir_uri=log_dir,\n",
    "        image=tf_image\n",
    "    ).set_display_name(\"Visualization\")\n",
    "\n",
    "    confusion_matrix_url = f\"minio://{log_bucket}/{confusion_matrix_log_dir}\"\n",
    "\n",
    "    prep_task = prep_op().after(prepare_tb_task).set_display_name(\"Preprocess & Transform\")\n",
    "    prep_task.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    copy_model = cp_op(prep_task.outputs['output_data'], \"/model/dataset\").add_pvolumes({\"/model\": dsl.PipelineVolume(pvc=dist_volume)}).after(prep_task)\n",
    "    copy_model.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    ls_task = ls_op(\"/model\").add_pvolumes({\"/model\": dsl.PipelineVolume(pvc=dist_volume)}).after(copy_model)\n",
    "    ls_task.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    train_task = pytorch_job_op(\n",
    "        name=\"pytorch-bert\", \n",
    "        namespace=namespace, \n",
    "        master_spec=\n",
    "        {\n",
    "          \"replicas\": 1,\n",
    "          \"imagePullPolicy\": \"Always\",\n",
    "          \"restartPolicy\": \"OnFailure\",\n",
    "          \"template\": {\n",
    "            \"metadata\": {\n",
    "              \"annotations\": {\n",
    "                \"sidecar.istio.io/inject\": \"false\"\n",
    "              }\n",
    "            },\n",
    "            \"spec\": {\n",
    "              \"containers\": [\n",
    "                {\n",
    "                  \"name\": \"pytorch\",\n",
    "                  \"image\": \"jagadeeshj/pytorch_samples:v1.5-gpu\",\n",
    "                  \"command\": [\"python3\", \"bert/agnews_classification_pytorch.py\"],\n",
    "                  \"args\": [\n",
    "                    \"--dataset_path\", \"/model/dataset\",\n",
    "                    \"--checkpoint_dir\", \"/model/checkpoint\",\n",
    "                    \"--script_args\", f\"model_name=bert.pth,num_samples={num_samples},confusion_matrix_url={confusion_matrix_url}\",\n",
    "                    \"--tensorboard_root\", log_dir,\n",
    "                    \"--ptl_args\", f\"max_epochs={max_epochs},profiler=pytorch,gpus={gpus},accelerator=ddp,num_nodes={num_nodes}\"\n",
    "                  ],\n",
    "                  \"ports\": [\n",
    "                    {\n",
    "                      \"containerPort\": 24456,\n",
    "                      \"name\": \"pytorchjob-port\"\n",
    "                    }\n",
    "                  ],\n",
    "                  \"resources\": {\n",
    "                    \"limits\": {\n",
    "                      \"nvidia.com/gpu\": 1\n",
    "                    }\n",
    "                  },\n",
    "                  \"volumeMounts\": [\n",
    "                    {\n",
    "                      \"mountPath\": \"/model\",\n",
    "                      \"name\": \"model-volume\"\n",
    "                    }\n",
    "                  ]\n",
    "                }\n",
    "              ],\n",
    "              \"volumes\": [\n",
    "                {\n",
    "                  \"name\": \"model-volume\",\n",
    "                  \"persistentVolumeClaim\": {\n",
    "                    \"claimName\": dist_volume\n",
    "                  }\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        }, \n",
    "        worker_spec=\n",
    "        {\n",
    "          \"replicas\": 1,\n",
    "          \"imagePullPolicy\": \"Always\",\n",
    "          \"restartPolicy\": \"OnFailure\",\n",
    "          \"template\": {\n",
    "            \"metadata\": {\n",
    "              \"annotations\": {\n",
    "                \"sidecar.istio.io/inject\": \"false\"\n",
    "              }\n",
    "            },\n",
    "            \"spec\": {\n",
    "              \"containers\": [\n",
    "                {\n",
    "                  \"name\": \"pytorch\",\n",
    "                  \"image\": \"jagadeeshj/pytorch_samples:v1.5-gpu\",\n",
    "                  \"command\": [\"python3\", \"bert/agnews_classification_pytorch.py\"],\n",
    "                  \"args\": [\n",
    "                    \"--dataset_path\", \"/model/dataset\",\n",
    "                    \"--checkpoint_dir\", \"/model/checkpoint\",\n",
    "                    \"--script_args\", f\"model_name=bert.pth,num_samples={num_samples},confusion_matrix_url={confusion_matrix_url}\",\n",
    "                    \"--tensorboard_root\", log_dir,\n",
    "                    \"--ptl_args\", f\"max_epochs={max_epochs},profiler=pytorch,gpus={gpus},accelerator=ddp,num_nodes={num_nodes}\"\n",
    "                  ],\n",
    "                  \"ports\": [\n",
    "                    {\n",
    "                      \"containerPort\": 24456,\n",
    "                      \"name\": \"pytorchjob-port\"\n",
    "                    }\n",
    "                  ],\n",
    "                  \"resources\": {\n",
    "                    \"limits\": {\n",
    "                      \"nvidia.com/gpu\": 1\n",
    "                    }\n",
    "                  },\n",
    "                  \"volumeMounts\": [\n",
    "                    {\n",
    "                      \"mountPath\": \"/model\",\n",
    "                      \"name\": \"model-volume\"\n",
    "                    }\n",
    "                  ]\n",
    "                }\n",
    "              ],\n",
    "              \"volumes\": [\n",
    "                {\n",
    "                  \"name\": \"model-volume\",\n",
    "                  \"persistentVolumeClaim\": {\n",
    "                    \"claimName\": dist_volume\n",
    "                  }\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    ).after(ls_task)\n",
    "    train_task.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    copy_mar = cp_op(\"/model/checkpoint\", \"\").add_pvolumes({\"/model\": dsl.PipelineVolume(pvc=dist_volume)}).after(train_task)\n",
    "    copy_mar.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    ls_task2 = ls_op(copy_mar.outputs['destination_directory']).after(copy_mar)\n",
    "    ls_task2.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "\n",
    "    minio_tb_upload = (\n",
    "        minio_op(\n",
    "            bucket_name=\"mlpipeline\",\n",
    "            folder_name=lThe volume doog_dir,\n",
    "            input_path=/,\n",
    "            filename=\"\",\n",
    "        ).add_pvolumes({\"/model\": dsl.PipelineVolume(pvc=dist_volume)})\n",
    "        .after(train_task)\n",
    "        .set_display_name(\"Tensorboard Events Pusher\")\n",
    "    )\n",
    "    minio_mar_upload = (\n",
    "        minio_op(\n",
    "            bucket_name=\"mlpipeline\",\n",
    "            folder_name=mar_path,\n",
    "            input_path=train_task.outputs[\"checkpoint_dir\"],\n",
    "            filename=\"bert_test.mar\",\n",
    "        )\n",
    "        .after(train_task)\n",
    "        .set_display_name(\"Mar Pusher\")\n",
    "    )\n",
    "    minio_config_upload = (\n",
    "        minio_op(\n",
    "            bucket_name=\"mlpipeline\",\n",
    "            folder_name=config_prop_path,\n",
    "            input_path=train_task.outputs[\"checkpoint_dir\"],\n",
    "            filename=\"config.properties\",\n",
    "        )\n",
    "        .after(train_task)\n",
    "        .set_display_name(\"Conifg Pusher\")\n",
    "    )\n",
    "\n",
    "    model_uri = str(model_uri)\n",
    "    isvc_yaml = \"\"\"\n",
    "    apiVersion: \"serving.kubeflow.org/v1beta1\"\n",
    "    kind: \"InferenceService\"\n",
    "    metadata:\n",
    "      name: {}\n",
    "      namespace: {}\n",
    "    spec:\n",
    "      predictor:\n",
    "        serviceAccountName: sa\n",
    "        pytorch:\n",
    "          storageUri: {}\n",
    "          resources:\n",
    "            limits:\n",
    "              memory: 4Gi   \n",
    "    \"\"\".format(\n",
    "        deploy, namespace, model_uri\n",
    "    )\n",
    "\n",
    "    # For GPU inference use below yaml with gpu count and accelerator\n",
    "    gpu_count = \"1\"\n",
    "    accelerator = \"nvidia-tesla-p4\"\n",
    "    isvc_gpu_yaml = \"\"\"\n",
    "    apiVersion: \"serving.kubeflow.org/v1beta1\"\n",
    "    kind: \"InferenceService\"\n",
    "    metadata:\n",
    "      name: {}\n",
    "      namespace: {}\n",
    "    spec:\n",
    "      predictor:\n",
    "        serviceAccountName: sa\n",
    "        pytorch:\n",
    "          storageUri: {}\n",
    "          resources:\n",
    "            limits:\n",
    "              memory: 4Gi   \n",
    "              nvidia.com/gpu: {}\n",
    "          nodeSelector:\n",
    "            cloud.google.com/gke-accelerator: {}\n",
    "\"\"\".format(\n",
    "        deploy, namespace, model_uri, gpu_count, accelerator\n",
    "    )\n",
    "    # Update inferenceservice_yaml for GPU inference\n",
    "    deploy_task = (\n",
    "        deploy_op(action=\"apply\", inferenceservice_yaml=isvc_yaml)\n",
    "        .after(minio_mar_upload)\n",
    "        .set_display_name(\"Deployer\")\n",
    "    )\n",
    "\n",
    "    dsl.get_pipeline_conf().add_op_transformer(\n",
    "        use_k8s_secret(\n",
    "            secret_name=\"mlpipeline-minio-artifact\",\n",
    "            k8s_secret_key_to_env={\n",
    "                \"secretkey\": \"MINIO_SECRET_KEY\",\n",
    "                \"accesskey\": \"MINIO_ACCESS_KEY\",\n",
    "            },\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_conf = kfp.dsl.PipelineConf()\n",
    "# pipeline_conf.data_passing_method = volume_based_data_passing_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile pipeline\n",
    "compiler.Compiler().compile(pytorch_bert, 'pytorch.tar.gz', type_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://istio-ingressgateway.istio-system.svc.cluster.local/pipeline/#/runs/details/33df636d-17db-454e-ab9b-fc915af122fa\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute pipeline\n",
    "run = client.run_pipeline(my_experiment.id, 'pytorch-bert', 'pytorch.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait for inference service below to go to `READY True` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         URL                                                       READY   PREV   LATEST   PREVROLLEDOUTREVISION   LATESTREADYREVISION                  AGE\n",
      "bertserve    http://bertserve.kubeflow-user-example-com.example.com    True           100                              bertserve-predictor-default-zckhh    44h\n",
      "torchserve   http://torchserve.kubeflow-user-example-com.example.com   True           100                              torchserve-predictor-default-tdknk   47h\n"
     ]
    }
   ],
   "source": [
    "!kubectl get isvc $DEPLOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Inferenceservice name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bertserve.kubeflow-user-example-com.example.com'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INFERENCE_SERVICE_LIST = ! kubectl get isvc {DEPLOY_NAME} -n {NAMESPACE} -o json | python3 -c \"import sys, json; print(json.load(sys.stdin)['status']['url'])\"| tr -d '\"' | cut -d \"/\" -f 3\n",
    "INFERENCE_SERVICE_NAME = INFERENCE_SERVICE_LIST[0]\n",
    "INFERENCE_SERVICE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying 10.100.251.14:80...\n",
      "* TCP_NODELAY set\n",
      "* Connected to istio-ingressgateway.istio-system.svc.cluster.local (10.100.251.14) port 80 (#0)\n",
      "> POST /v1/models/bert:predict HTTP/1.1\n",
      "> Host: bertserve.kubeflow-user-example-com.example.com\n",
      "> User-Agent: curl/7.68.0\n",
      "> Accept: */*\n",
      "> Cookie: authservice_session=MTYyMzI1NDI0NHxOd3dBTkVGU1UxaElXRXN5VUVKTVJrZFVUMWhDU1VoVlNVMUhSRFZaVVRWQlNrVkhORTAzUTFWTFVqZExSa0pHVmpWU016SmFOa0U9fO86sBQIDoqYUxX9ffUnG7xS8xyysaWppWJa0c3QBRJd\n",
      "> Content-Length: 84\n",
      "> Content-Type: application/x-www-form-urlencoded\n",
      "> \n",
      "} [84 bytes data]\n",
      "* upload completely sent off: 84 out of 84 bytes\n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< content-length: 33\n",
      "< content-type: application/json; charset=UTF-8\n",
      "< date: Thu, 10 Jun 2021 08:51:03 GMT\n",
      "< server: istio-envoy\n",
      "< x-envoy-upstream-service-time: 535\n",
      "< \n",
      "{ [33 bytes data]\n",
      "100   117  100    33  100    84     52    132 --:--:-- --:--:-- --:--:--   214\n",
      "* Connection #0 to host istio-ingressgateway.istio-system.svc.cluster.local left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -v -H \"Host: $INFERENCE_SERVICE_NAME\" -H \"Cookie: $COOKIE\" \"$INGRESS_GATEWAY/v1/models/$MODEL_NAME:predict\" -d @./bert/sample.txt > bert_prediction_output.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [\"\\\"Sci/Tech\\\"\"]}"
     ]
    }
   ],
   "source": [
    "! cat bert_prediction_output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying 10.100.251.14:80...\n",
      "* TCP_NODELAY set\n",
      "* Connected to istio-ingressgateway.istio-system.svc.cluster.local (10.100.251.14) port 80 (#0)\n",
      "> POST /v1/models/bert:explain HTTP/1.1\n",
      "> Host: bertserve.kubeflow-user-example-com.example.com\n",
      "> User-Agent: curl/7.68.0\n",
      "> Accept: */*\n",
      "> Cookie: authservice_session=MTYyMzI1NDI0NHxOd3dBTkVGU1UxaElXRXN5VUVKTVJrZFVUMWhDU1VoVlNVMUhSRFZaVVRWQlNrVkhORTAzUTFWTFVqZExSa0pHVmpWU016SmFOa0U9fO86sBQIDoqYUxX9ffUnG7xS8xyysaWppWJa0c3QBRJd\n",
      "> Content-Length: 84\n",
      "> Content-Type: application/x-www-form-urlencoded\n",
      "> \n",
      "} [84 bytes data]\n",
      "* upload completely sent off: 84 out of 84 bytes\n",
      "100    84    0     0  100    84      0      1  0:01:24  0:00:52  0:00:32     000:02     00:30  0:00:12     08  0:00:04     0  0   0      1  0:01:24  0:00:45  0:00:39     0* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< content-length: 320\n",
      "< content-type: application/json; charset=UTF-8\n",
      "< date: Thu, 10 Jun 2021 08:23:36 GMT\n",
      "< server: istio-envoy\n",
      "< x-envoy-upstream-service-time: 52441\n",
      "< \n",
      "{ [320 bytes data]\n",
      "100   404  100   320  100    84      6      1  0:01:24  0:00:52  0:00:32    77\n",
      "* Connection #0 to host istio-ingressgateway.istio-system.svc.cluster.local left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -v -H \"Host: $INFERENCE_SERVICE_NAME\" -H \"Cookie: $COOKIE\" \"$INGRESS_GATEWAY/v1/models/$MODEL_NAME:explain\" -d @./bert/sample.txt  > bert_explaination_output.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"explanations\": [{\"words\": [\"[CLS]\", \"bloomberg\", \"has\", \"reported\", \"on\", \"the\", \"economy\", \"[SEP]\"], \"importances\": [0.49803253502586686, -0.042289041470624116, -0.2269101439114476, 0.15573707990586028, 0.0867725310070807, 0.17919607383818434, 0.5255456841947312, -0.5988271940782108], \"delta\": 0.12081503337965546}]}"
     ]
    }
   ],
   "source": [
    "! cat bert_explaination_output.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanations': [{'words': ['[CLS]',\n",
       "    'bloomberg',\n",
       "    'has',\n",
       "    'reported',\n",
       "    'on',\n",
       "    'the',\n",
       "    'economy',\n",
       "    '[SEP]'],\n",
       "   'importances': [0.49803253502586686,\n",
       "    -0.042289041470624116,\n",
       "    -0.2269101439114476,\n",
       "    0.15573707990586028,\n",
       "    0.0867725310070807,\n",
       "    0.17919607383818434,\n",
       "    0.5255456841947312,\n",
       "    -0.5988271940782108],\n",
       "   'delta': 0.12081503337965546}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations_json = json.loads(open(\"./bert_explaination_output.json\", \"r\").read())\n",
    "explanations_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_json = json.loads(open(\"./bert_prediction_output.json\", \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "attributions = explanations_json[\"explanations\"][0]['importances']\n",
    "tokens = explanations_json[\"explanations\"][0]['words']\n",
    "delta = explanations_json[\"explanations\"][0]['delta']\n",
    "\n",
    "attributions = torch.tensor(attributions)\n",
    "pred_prob = 0.75\n",
    "pred_class = prediction_json[\"predictions\"][0]\n",
    "true_class = \"Business\"\n",
    "attr_class =\"world\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from captum.attr import visualization\n",
    "vis_data_records =[]\n",
    "vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pred_prob,\n",
    "                            pred_class,\n",
    "                            true_class,\n",
    "                            attr_class,\n",
    "                            attributions.sum(),       \n",
    "                            tokens,\n",
    "                            delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = visualization.visualize_text(vis_data_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization appreas as below\n",
    "![viz1.png](./viz1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! kubectl delete --all isvc -n $NAMESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl delete pod --field-selector=status.phase==Succeeded -n $NAMESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
